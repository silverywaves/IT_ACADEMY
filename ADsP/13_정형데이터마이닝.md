## 정형데이터마이닝
### 데이터 마이닝 개요
#### 데이터마이닝
- 모든 사용가능한 원천데이터를 기반으로 감춰진 지식, 기대하지 못했던 경향, 새로운 규칙 발견
  => 실제 비즈니스 의사결정 등에 유용한 정보로 활용
- 기업이 보유하고 있는 일일 거래데이터, 고객데이터, 상품데이터, 각종 마케팅 활동의 고객 반응데이터, 그 외 외부 데이터를 포함


---

#### 추진단계
1. 목적정의
    - 데이터마이닝 도입 목적을 명확하게 함

2. 데이터 준비
    - 데이터 정제(Cleaning)을 통해 품질 확보
    - 필요시 데이터 양을 충분하게 확보

3. 데이터 가공
    - 목적변수 정의
    - 필요한 데이터를 데이터 마이닝 소프트웨어에 적용할 수 있게 가공, 준비

4. 데이터마이닝 기법 적용
    - 목적에 맞는 모델 선택
    - SW 사용하는데 필요한 값 지정

5. 검증


---

#### 대표적 기법
1. 분류(Classification)
    - 새롭게 나타난 현상 검토 -> 기존의 분류, 정의된 집합에 배정
    - 의사결정나무, memory-base reasoning 등

2. 추정(Estimation)
    - 주어진 입력 데이터를 사용하여 알려지지 않은 결과의 값 추정
    - 연속된 변수의 값 추정, 신경망 모형

3. 연관분석(Association Analysis)
    - 장바구니 분석 => '같이 팔리는 물건' 같이 아이템의 연관성 파악
    - 카탈로그 배열 및 교차판매, 공격적 판촉행사 등의 마케팅 기획

4. 예측(Prediction)
    - '미래'에 대한 것을 예측, 추정하는 것을 제외시 분료 or 추정과 동일
    - 장바구니분석, 의사결정나무, 신경망모형

5. 군집(Clustering)
    - 레코드 자체가 가진 레코드들과의 유사성
    - 유사성으로 그룹화, 이질성으로 세분화

6. 기술(Description)
    - 데이터가 가진 특징 및 의미를 단순하게 설명


#### 데이터 마이닝의 분석방법

![분석방법](https://github.com/silverywaves/IT_ACADEMY/assets/155939946/404e8885-a023-4764-8f97-5e823c28d9b4)



---

## 분류분석
### 1. 로지스틱 회귀분석(Logistic Regression)
- 독립변수는 연속형, 종속변수(y)가 범주형인 경우 적용되는 회귀분석 모형
- 종속변수가 성공/실패, 사망/생존과 같이 이항변수(0, 1)로 되어있을 때
- 종속변수와 독립변수간의 관계식을 이용하여 집단을 분류하고자 할 때
- 종속변수를 전체 실수 범위로 확장하여 분석하고 sigmoid 함수를 사용해 연속형 0~1 값으로 변경


![로지스틱](https://github.com/silverywaves/IT_ACADEMY/assets/155939946/d0714f58-5b66-4044-b722-179e78160536)


![로지스틱2](https://github.com/silverywaves/IT_ACADEMY/assets/155939946/2cbe6fdc-644e-4252-8f78-d1fa5e378634)


** 회귀식에 대한 해석방법이 선형회귀와 다름


---

### 2. 의사결정나무(Decision Tree) 모형
- 의사결정 규칙을 나무구조로 나타내 전체 자료를 몇 개의 소집단으로 분류 or 예측
- 분석방법이 직관적이고 쉬움

![의사결정나무](https://github.com/silverywaves/IT_ACADEMY/assets/155939946/844b891b-158c-4c0b-9ca6-f4a0d2c89405)


#### 특징
  - 목적 : 새로운 데이터를 분류 or 값 예츨
  - 분리변수 p 차원 공간에 대해 현재 분할은 이전 분할에 영향 받음
  - 부모마디 자식마디의 순수도가 증가하도록 분류나무 형성(불순도 감소)


#### 종류
  - 목표변수(=종속변수)가 이산형인 경우 분류나무, 연속형인 경우 회귀나무


#### 장점
  - 구조가 단순하여 해석하기 용이
  - 비모수적 모형 -> 선형성, 정규성, 등분산성 등 수학적 가정 불필요
  - 범주형(이산형)과 수치형(연속형) 변수 모두 사용 가능


#### 단점
  - 분류 기준값의 경계선 부근의 자료값에 대해서는 오차가 큼(비연속성)
  - 로지스틱 회귀와 같이 예측변수의 효과를 파악하기 어려움
  - 새로운 자료에 대한 예측 불안정


#### 결정규칙
  - 분리기준(Split Criterion)
    - 새로운 가지를 만드는 기준은 어떻게 정하는가?
    - 순수도가 높아지는 방향으로 분리
    - 불확실성이 낮아지는 방향으로 분리
   
  - 정지규칙(Stopping Rule) 
    - 더이상 분리가 일어나지 않고 현재의 마디가 최종마디가 되도록 함
    - '불순도 감소량이 아주 작을 때 정지
 
  - 가지치기 규칙(Pruning Rule)
    - 어느 가지를 쳐내야 예측력이 좋은 나무가 될까?
    - 최종 노드가 너무 많으면 Overfitting(과대적합) 가능성 높아지는데, 이를 해결하기 위해 사용
    - 가지치기 규칙은 별도 규칙을 제공하거나 경험에 의해 실행 가능
    - 가지치기의 비용함수(Cost Function)을 최소로 하는 분기를 찾을 수 있도록 학습
    - Information Gain : 어떤 속성을 선택함으로서 데이터를 더 잘 구분 (불확실성 감소)


---

### 3. 불순도 측정 지표
- 목표변수가 범주형일때 (분류에서 사용)
  - 지니지수, 엔트로피지수, 카이제곱 통계량 <= 가장 작은 값을 가지는 분석 선택


1. 지니지수
    - 불순도 측정 지표
    - 값이 작을수록 순수도가 높음(분류 잘됨)
    - 가장 작은 값을 갖는 예측변수와 이때의 최적 분리에 의해 자식마디 형성

2. 엔트로피 지수
    - 불순도 측정 지표
    - 가장 작은 값을 갖는 방법 선택


<img width="497" alt="지니, 엔트로피" src="https://github.com/silverywaves/IT_ACADEMY/assets/155939946/532d0ab2-18b0-4758-a457-678cabbae698">

    

3. 카이제곱 통계량
   - 가장 작은 값을 갖는 방법 선택

<img width="570" alt="카이제곱" src="https://github.com/silverywaves/IT_ACADEMY/assets/155939946/377a5210-2cc3-47df-aa82-25be5258b686">


---

### 4. 의사결정나무 알고리즘
- CHAID, CART, ID2, C5.0, C4.5 등
- 하향식 접근 방법 이용
- 알고리즘별 분리, 정지 기준변수 선택법

![의사결정나무기준변수선택](https://github.com/silverywaves/IT_ACADEMY/assets/155939946/9e4f4fea-a2f0-4c52-a6e9-2c6c04a8ca93)



